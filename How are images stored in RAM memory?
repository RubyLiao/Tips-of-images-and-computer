The ram can be modeled as a one dimensional array of words, so any kind of data you load into memory will be more or
less organized in part/parts of the ram.
When it comes to images there is a big difference between what is saved on disk and what you need to display the image
as in general and except for raw format image types what is saved on disk is in a compressed form (lossy or lossless).
However after loading the image data from file and to be able to display it, decompression kicks in and reconstructs
the array of pixels with some meta data describing how they are arranged.
For example: let’s imagine we are loading 800*600 color image that has transparency and every color represented with
one byte.

It will look in memory like this(or something similar)
Address 000000 : 32-bit integer representing the width = 800
Address 000001 : 32-bit integer representing the height= 600
Address 000002 : 32-bit integer representing the format of the data = a number that represents the sequence of colors
like “RGBA”

Address 000003: start of the pixels array and containing the color of the first pixel as 32-bit integer which can be
viewed as 4-bytes: first byte = red value, second byte = green value, third byte = blue value, fourth byte = transparency value

Address 480003: end of the pixels array and containing the color of the last pixel as 32-bit integer which can be viewed
as 4-bytes: first byte = red value, second byte = green value, third byte = blue value, fourth byte = transparency value

so in a programming language you will need to keep the pixels in some variable like this pixels[800*600] and to access the
color at the pixel with position (x, y) you will access pixels[x + width * y] and if you just need the red value you will
need to extract the corresponding byte from the color value.

from Quaro: https://qr.ae/psFlno